@inproceedings{silvestre2025tempo,
  title={Tempo: Compiled Dynamic Deep Learning with Symbolic Dependence Graphs},
  author={Silvestre, Pedro F and Pietzuch, Peter},
  booktitle={Proceedings of the ACM SIGOPS 31st Symposium on Operating Systems Principles},
  pages={572--588},
  abstract={Deep learning (DL) algorithms are often defined in terms of temporal relationships: a tensor at one timestep may depend on tensors from earlier or later timesteps. Such dynamic dependencies (and corresponding dynamic tensor shapes) are difficult to express and optimize: while eager DL systems support such dynamism, they cannot apply compiler-based optimizations; graph-based systems require static tensor shapes, which forces users to pad tensors or break-up programs into multiple static graphs.
We describe Tempo, a new DL system that combines the dynamism of eager execution with the whole-program optimizations of graph-based compilation. Tempo achieves this through a declarative programming model with recurrent tensors, which include explicit temporal dimensions. Temporal dimensions can be indexed using symbolic expressions to express dynamic dependencies on past and future tensors. Based on this, Tempo constructs a symbolic dependence graph, which concisely encodes dynamic dependencies between operators, and applies whole-program optimizations, such as algebraic simplifications, vectorization, tiling, and fusion. By tiling dynamic dependencies into static-size blocks, Tempo can also reuse existing static code-generators. It then uses a polyhedral model to find a feasible execution schedule, which includes memory management operations. We show that Tempo achieves a 7× speedup over JAX for Llama-3.2-3B decoding; for reinforcement learning algorithms, Tempo achieves a 54× speedup, with 16× lower peak memory usage.},
  year={2025}
}

@inproceedings{silvestre2025systems,
  title={Systems Opportunities for LLM Fine-Tuning using Reinforcement Learning},
  author={Silvestre, Pedro F and Pietzuch, Peter},
  booktitle={Proceedings of the 5th Workshop on Machine Learning and Systems},
  pages={90--99},
  abstract={Reinforcement learning-based fine-tuning (RLFT) has emerged as a crucial workload for enhancing large language models (LLMs). RLFT workflows are challenging, involving nested loops, multiple models, dynamically shaped tensors and interleaving sequential generation and parallel inference tasks. Despite these complexities, current RLFT engines rely on coarse-grained algorithm representations, treating each component as an independently optimized black-box. As a result, RLFT engines suffer from redundant computations, scheduling overhead, inefficient memory management, and missed opportunities for parallelism.
We argue that a fine-grained representation is needed to enable holistic optimization for RLFT workloads. Additionally, we demonstrate that existing declarative deep learning engines fail to optimize RLFT workloads end-to-end due to their need for static tensor shapes and loop bounds, leading to excessive peak memory usage and unnecessary computations. Through micro-benchmarks, we quantify these inefficiencies and show that addressing them could enable more efficient and flexible execution. We propose an RLFT system design based on a fine-granularity representation, opening the door to generalizable optimizations, and paving the way for more scalable and efficient RLFT systems.},
  year={2025}
}

@inproceedings{10.1145/3448016.3457320,
author = {Silvestre, Pedro F. and Fragkoulis, Marios and Spinellis, Diomidis and Katsifodimos, Asterios},
title = {Clonos: Consistent Causal Recovery for Highly-Available Streaming Dataflows},
year = {2021},
isbn = {9781450383431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3448016.3457320},
doi = {10.1145/3448016.3457320},
abstract = {Stream processing lies in the backbone of modern businesses, being employed for mission
critical applications such as real-time fraud detection, car-trip fare calculations,
traffic management, and stock trading. Large-scale applications are executed by scale-out
stream processing systems on thousands of long-lived operators, which are subject
to failures. Recovering from failures fast and consistently are both top priorities,
yet they are only partly satisfied by existing fault tolerance methods due to the
strong assumptions these make. In particular, prior solutions fail to address consistency
in the presence of nondeterminism, such as calls to external services, asynchronous
timers and processing-time windows. This paper describes Clonos, a fault tolerance
approach that achieves fast, local operator recovery with exactly-once guarantees
and high availability by instantly switching to passive standby operators. Clonos
enforces causally consistent recovery, including output deduplication, by tracking
nondeterminism within the system through causal logging. To implement Clonos we re-engineered
many of the internal subsystems of a state of the art stream processor. We evaluate
Clonos' overhead and recovery on the Nexmark benchmark against Apache Flink. Clonos
achieves instant recovery with negligible overhead and, unlike previous work, does
not make assumptions on the deterministic nature of operators.},
booktitle = {Proceedings of the 2021 International Conference on Management of Data},
pages = {1637–1650},
numpages = {14},
keywords = {cloud computing, stream processing, exactly-once, fault-tolerance, high-availability, consistency},
location = {Virtual Event, China},
series = {SIGMOD/PODS '21}
}




